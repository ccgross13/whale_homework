{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  A Whale off the Port(folio)\n",
    "\n",
    " In this assignment, you'll get to use what you've learned this week to evaluate the performance among various algorithmic, hedge, and mutual fund portfolios and compare them against the S&P 500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this section, you will need to read the CSV files into DataFrames and perform any necessary data cleaning steps. After cleaning, combine all DataFrames into a single DataFrame.\n",
    "\n",
    "Files:\n",
    "1. whale_returns.csv\n",
    "2. algo_returns.csv\n",
    "3. sp500_history.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whale Returns\n",
    "\n",
    "Read the Whale Portfolio daily returns and clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading whale returns\n",
    "whale_returns_csv = Path(\"/Users/connor/Desktop/Starter_Code/Resources/whale_returns.csv\")\n",
    "# YOUR CODE HERE\n",
    "whale_returns_df = pd.read_csv(whale_returns_csv, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "whale_returns_df.sort_index(inplace=True)\n",
    "whale_returns_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count nulls\n",
    "# YOUR CODE HERE\n",
    "whale_returns_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop nulls\n",
    "# YOUR CODE HERE\n",
    "whale_returns_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whale_returns_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmic Daily Returns\n",
    "\n",
    "Read the algorithmic daily returns and clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading algorithmic returns\n",
    "algo_returns_csv = Path(\"Resources/algo_returns.csv\")\n",
    "# YOUR CODE HERE\n",
    "algo_returns_df = pd.read_csv(algo_returns_csv, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "algo_returns_df.sort_index(inplace=True)\n",
    "algo_returns_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count nulls\n",
    "# YOUR CODE HERE\n",
    "algo_returns_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop nulls\n",
    "# YOUR CODE HERE\n",
    "algo_returns_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algo_returns_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 Returns\n",
    "\n",
    "Read the S&P500 Historic Closing Prices and create a new daily returns DataFrame from the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading S&P 500 Closing Prices\n",
    "sp500_history_csv = Path(\"Resources/sp500_history.csv\")\n",
    "# YOUR CODE HERE\n",
    "sp500_history_df = pd.read_csv(sp500_history_csv, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "sp500_history_df.sort_index(inplace=True)\n",
    "sp500_history_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Data Types\n",
    "# YOUR CODE HERE\n",
    "sp500_history_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Data Types -- Removing $ sign from Close value\n",
    "# YOUR CODE HERE\n",
    "sp500_history_df['Close'] = sp500_history_df['Close'].str.replace('$', '')\n",
    "sp500_history_df['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Data Types -- Converting 'Close' from 'object' to 'float'\n",
    "sp500_history_df['Close'] = sp500_history_df['Close'].astype('float')\n",
    "sp500_history_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Daily Returns\n",
    "# YOUR CODE HERE\n",
    "sp500_returns = sp500_history_df.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop nulls\n",
    "# YOUR CODE HERE\n",
    "sp500_returns.dropna(inplace=True)\n",
    "sp500_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename Column\n",
    "# YOUR CODE HERE\n",
    "sp500_returns = sp500_returns.rename(columns={\"Close\": \"S&P 500\"})\n",
    "sp500_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Whale, Algorithmic, and S&P 500 Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all DataFrames into a single DataFrame\n",
    "# YOUR CODE HERE\n",
    "joined_returns_df = pd.concat([whale_returns_df, algo_returns_df, sp500_returns], axis=\"columns\", join=\"inner\")\n",
    "joined_returns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Analysis\n",
    "\n",
    "In this section, you will calculate and visualize performance and risk metrics for the portfolios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "Calculate and Plot the daily returns and cumulative returns. Does any portfolio outperform the S&P 500? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot daily returns\n",
    "# YOUR CODE HERE\n",
    "daily_returns = joined_returns_df.plot(figsize=(20,10))\n",
    "daily_returns.set_ylabel(\"Returns %\")\n",
    "daily_returns.set_title(\"Daily Returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot cumulative returns\n",
    "# YOUR CODE HERE\n",
    "initial_investment = 1000\n",
    "cum_ret = (1 + joined_returns_df).cumprod()\n",
    "cumulative_returns_plot = (initial_investment * cum_ret).plot(figsize=(20,10))\n",
    "cumulative_returns_plot.set_ylabel(\"Returns $\")\n",
    "cumulative_returns_plot.set_title(\"Cumulative Returns $\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Algo 2 portfolio outperforms the S&P 500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk\n",
    "\n",
    "Determine the _risk_ of each portfolio:\n",
    "\n",
    "1. Create a box plot for each portfolio. \n",
    "2. Calculate the standard deviation for all portfolios\n",
    "4. Determine which portfolios are riskier than the S&P 500\n",
    "5. Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box plot to visually show risk\n",
    "# YOUR CODE HERE\n",
    "box_plot = joined_returns_df.plot.box()\n",
    "box_plot.set_xticklabels(labels=joined_returns_df, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a box plot for each of the returns. Which box has the largest spread? Which has the smallest spread?\n",
    "Tiger Global Management has the largest spread. Paulson & Co. has the smallest spread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Standard Deviations\n",
    "# Calculate the standard deviation for each portfolio. \n",
    "# Which portfolios are riskier than the S&P 500?\n",
    "# YOUR CODE HERE\n",
    "daily_std = joined_returns_df.std()\n",
    "print(daily_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daily_std_hl = daily_std.sort_values(ascending=False)\n",
    "print(daily_std_hl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine which portfolios are riskier than the S&P 500\n",
    "# YOUR CODE HERE\n",
    "daily_std > daily_std_hl['S&P 500']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the annualized standard deviation (252 trading days)\n",
    "# YOUR CODE HERE\n",
    "annualized_std = daily_std * np.sqrt(252) * 100\n",
    "print(annualized_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the standard deviation for each portfolio. Which portfolios are riskier than the S&P 500?\n",
    "Tiger Global Management and Berkshire Hathaway have riskier portfolios than the S&P 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics\n",
    "\n",
    "Risk changes over time. Analyze the rolling statistics for Risk and Beta. \n",
    "\n",
    "1. Plot the rolling standard deviation of the various portfolios along with the rolling standard deviation of the S&P 500 (consider a 21 day window). Does the risk increase for each of the portfolios at the same time risk increases in the S&P? The risk for each portfolio tracks with the general direction of the S&P 500.\n",
    "2. Construct a correlation table for the algorithmic, whale, and S&P 500 returns. Which returns most closely mimic the S&P? The Algo 1 retuns closely mimic the S&P 500\n",
    "2. Choose one portfolio and plot a rolling beta between that portfolio's returns and S&P 500 returns. Does the portfolio seem sensitive to movements in the S&P 500? The Soros Fund Management portfolio beta is lower than the S&P 500 beta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and plot the rolling standard deviation for\n",
    "# the S&P 500 and whale portfolios using a 21 trading day window\n",
    "# YOUR CODE HERE\n",
    "rolling_std_dev = joined_returns_df.rolling(window=21).std().plot(figsize =(20,10))\n",
    "rolling_std_dev.set_ylabel(\"Std Dev\")\n",
    "rolling_std_dev.set_title(\"Rolling Std Dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a correlation table\n",
    "# YOUR CODE HERE\n",
    "portfolio_corr = joined_returns_df.corr()\n",
    "sns.heatmap(portfolio_corr, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Beta for a single portfolio compared to the total market (S&P 500)\n",
    "# (Your graph may differ, dependent upon which portfolio you are comparing)\n",
    "# YOUR CODE HERE\n",
    "soros_covariance = joined_returns_df['SOROS FUND MANAGEMENT LLC'].cov(joined_returns_df['S&P 500'])\n",
    "variance_spy = joined_returns_df['S&P 500'].var()\n",
    "soros_beta = soros_covariance / variance_spy\n",
    "soros_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Exponentially Weighted Average \n",
    "\n",
    "An alternative way to calculate a rollwing window is to take the exponentially weighted moving average. This is like a moving window average, but it assigns greater importance to more recent observations. Try calculating the `ewm` with a 21 day half-life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (OPTIONAL) YOUR CODE HERE\n",
    "exp_wgh_ma = joined_returns_df.ewm(halflife=21,adjust=False).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpe Ratios\n",
    "In reality, investment managers and thier institutional investors look at the ratio of return-to-risk, and not just returns alone. (After all, if you could invest in one of two portfolios, each offered the same 10% return, yet one offered lower risk, you'd take that one, right?)\n",
    "\n",
    "Calculate and plot the annualized Sharpe ratios for all portfolios to determine which portfolio has the best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annualized Sharpe Ratios\n",
    "# YOUR CODE HERE\n",
    "portfolio_sharpe_ratios = (joined_returns_df.mean() * 252) / (joined_returns_df.std() * np.sqrt(252))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " plot() these sharpe ratios using a barplot.\n",
    " On the basis of this performance metric, do our algo strategies outperform both 'the market' and the whales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "# YOUR CODE HERE\n",
    "portfolio_sharpe_ratios.plot(kind=\"bar\", title=\"Sharpe Ratios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Returns\n",
    "\n",
    "In this section, you will build your own portfolio of stocks, calculate the returns, and compare the results to the Whale Portfolios and the S&P 500. \n",
    "\n",
    "1. Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock.\n",
    "2. Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock\n",
    "3. Join your portfolio returns to the DataFrame that contains all of the portfolio returns\n",
    "4. Re-run the performance and risk analysis with your portfolio to see how it compares to the others\n",
    "5. Include correlation analysis to determine which stocks (if any) are correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the first stock\n",
    "# YOUR CODE HERE\n",
    "google_returns_csv = Path(\"../Starter_Code/googl_google_finance - Sheet1.csv\")\n",
    "# YOUR CODE HERE\n",
    "google_returns_df = pd.read_csv(google_returns_csv, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "google_returns_df.sort_index(inplace=True)\n",
    "google_returns_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the second stock\n",
    "# YOUR CODE HERE\n",
    "aapl_returns_csv = Path(\"../Starter_Code/aapl_google_finance - Sheet1.csv\")\n",
    "# YOUR CODE HERE\n",
    "aapl_returns_df = pd.read_csv(aapl_returns_csv, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "aapl_returns_df.sort_index(inplace=True)\n",
    "aapl_returns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the third stock\n",
    "# YOUR CODE HERE\n",
    "msft_returns_csv = Path(\"../Starter_Code/msft_google_finance - Sheet1.csv\")\n",
    "# YOUR CODE HERE\n",
    "msft_returns_df = pd.read_csv(msft_returns_csv, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "msft_returns_df.sort_index(inplace=True)\n",
    "msft_returns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all stocks into a single DataFrame\n",
    "# YOUR CODE HERE\n",
    "custom_portfolio_df = pd.concat([google_returns_df, aapl_returns_df, msft_returns_df], axis=\"columns\", join=\"inner\")\n",
    "custom_portfolio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset the index\n",
    "# YOUR CODE HERE\n",
    "custom_portfolio_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_portfolio_df.reset_index(\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot so that each column of prices represents a unique symbol\n",
    "# YOUR CODE HERE\n",
    "custom_portfolio_df = custom_portfolio_df.pivot_table(values=\"Close\", index=\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Nulls\n",
    "# YOUR CODE HERE\n",
    "custom_portfolio_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR CODE HERE\n",
    "custom_portfolio_returns = custom_portfolio_df.pct_change()\n",
    "custom_portfolio_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate weighted portfolio returns\n",
    "\n",
    "weights = [.33, .33, .33]\n",
    "wght_portfolio_returns = custom_portfolio_returns.dot(weights)\n",
    "wght_port_ret = pd.DataFrame(data=wght_portfolio_returns)\n",
    "wght_port_ret.reset_index(\"Date\")\n",
    "columns = ['Custom Portfolio']\n",
    "wght_port_ret.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join your custom portfolio returns to the DataFrame that contains all of the portfolio returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add your \"Custom\" portfolio to the larger dataframe of fund returns\n",
    "# YOUR CODE HERE\n",
    "combined_df = pd.concat([joined_returns_df, wght_port_ret], axis=\"columns\", join=\"outer\", sort=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run the performance and risk analysis with your portfolio to see how it compares to the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk\n",
    "# YOUR CODE HERE\n",
    "combined_df.loc[combined_df.index.date == '2019-04-30']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annualized Sharpe Ratios\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include correlation analysis to determine which stocks (if any) are correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "nteract": {
   "version": "0.12.3"
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
